这是一份基于你提供的两份PDF课件（Lecture 10 和 Lecture 11）生成的**超详细学习笔记**。

这份笔记涵盖了从博弈论基础、博弈的定义，到对抗搜索的核心算法（Minimax、Alpha-Beta剪枝），以及处理非确定性环境（随机博弈）的所有知识点。

---

# 人工智能基础 (JC3001) 学习笔记
## 主题：对抗搜索 (Adversarial Search) & 博弈 (Games)

### 第一部分：课程背景与引入 (Introduction)
*对应课件：Lecture 10 Slide 1-8*

在之前的课程中，我们学习了无信息搜索、启发式搜索（A*）和局部搜索。这些搜索算法主要针对的是**确定性（Deterministic）**且**完全可观测（Fully-observable）**的环境，或者单智能体解决问题的场景。
然而，在**多智能体环境 (Multiagent Environments)** 中，情况变得复杂：
1.  **合作 (Cooperative)**：多个智能体为了共同目标协作。
2.  **竞争 (Competitive)**：智能体之间存在利益冲突，这是**博弈论 (Game Theory)** 研究的主要对象，也是本次笔记的核心——**对抗搜索**。

---

### 第二部分：博弈论基础与定义 (Game Theory Basics)
*对应课件：Lecture 10 Slide 9-17*

#### 1. AI中的“游戏”定义
AI研究中的“游戏”通常具有以下特征：
*   **确定性 (Deterministic)**
*   **轮流行动 (Turn-taking)**：如棋类。
*   **双人 (Two-player)**
*   **零和 (Zero-sum)**：一方的收益等于另一方的损失（收益之和为0）。
*   **完全信息 (Perfect Information)**：所有状态完全可观测。

> **注意**：这里的游戏不仅仅指娱乐游戏（如《暗黑破坏神3》通常不在此列），更指现实中的对抗建模，如海盗海域的巡逻、股票交易、警方部署等。

#### 2. 博弈的要素
*   **玩家 (Players)**：决策者（人、公司、政府）。
*   **动作 (Actions)**：玩家能做什么（投标、投票、移动棋子）。
*   **收益 (Payoffs)**：激励玩家的因素（利润、赢得比赛）。

#### 3. 博弈的两种主要表现形式
1.  **标准型/正规型 (Normal Form / Matrix Form)**：
    *   通常用于表示玩家看似“同时”行动的博弈。
    *   使用**矩阵**来列出动作和对应的收益。
2.  **扩展型 (Extensive Form)**：
    *   包含动作的**时间顺序**。
    *   使用**树 (Tree)** 结构来表示。

#### 4. 标准型博弈案例解析 (Normal Form Examples)
*课件中详细列举了多个矩阵案例，用于解释不同的博弈类型：*

*   **囚徒困境 (Prisoner’s Dilemma)**：
    *   **矩阵结构**：玩家1（行）和玩家2（列）选择合作(C)或背叛(D)。
    *   **收益分析**：如果双方都合作(C,C)，收益尚可（如-1,-1）；如果一方背叛另一方合作，背叛者获益最大（0），合作者损失最大（-3）；如果双方都背叛(D,D)，则是次差结果（-2,-2）。
    *   **关键点**：理性玩家倾向于选择背叛（Dominant Strategy），导致双方落入(D,D)的纳什均衡，而非全局最优的(C,C)。
*   **匹配硬币 (Matching Pennies)**：
    *   **矩阵结构**：两人出正面或反面。
    *   **含义**：纯粹的竞争博弈。一方希望两币相同（Match），另一方希望不同（Mismatch）。收益总和为0（零和博弈）。
*   **石头剪刀布 (Rock, Paper, Scissors)**：
    *   典型的零和博弈，没有纯策略纳什均衡。
*   **退出博弈 (Quitting Game) / 反协调博弈**：
    *   例子中是一个“谁先退出”的场景。这是一个**反协调 (Anti-coordination)** 博弈，即玩家倾向于做出与对方不同的选择。
*   **协调博弈 (Coordination Game)**：
    *   **例子**：靠左行驶还是靠右行驶？
    *   **分析**：只要双方选择一致（都左或都右），收益就是高的 (1,1)。如果不同，则发生碰撞 (0,0)。
*   **匹配博弈 (Matching Game)**：
    *   类似于协调博弈，双方都希望匹配上对方的行动 (Match)。

---

### 第三部分：扩展型博弈与博弈树 (Extensive Form & Game Trees)
*对应课件：Lecture 10 Slide 18-19*

扩展型博弈被定义为一个**搜索问题**，包含以下元素：
*   $S_0$：初始状态。
*   $Player(s)$：在状态 $s$ 轮到谁走。
*   $Actions(s)$：在状态 $s$ 有哪些合法动作。
*   $Result(s, a)$：**转移模型**，在 $s$ 做动作 $a$ 后的结果。
*   $TerminalTest(s)$：游戏是否结束（终端状态）。
*   $Utility(s, p)$：在终端状态 $s$，玩家 $p$ 的收益。

**案例：井字棋 (Tic-Tac-Toe)**
*   **树结构**：根节点是空棋盘。
*   **MAX (x)**：先手，试图最大化效用。
*   **MIN (o)**：后手，试图最小化MAX的效用（即最大化自己的效用）。
*   **终端节点**：根据输赢平，效用分别为 +1, -1, 0。

---

### 第四部分：非确定性搜索 (Non-deterministic Search)
*对应课件：Lecture 11 Slide 5-11*

在进入复杂的对抗搜索前，Lecture 11 首先回顾了非确定性环境。

#### 1. 错误的真空吸尘器世界 (Erratic Vacuum World)
*   **场景**：如果这是一个确定性环境，吸尘器吸地(Suck)就一定会干净。但在非确定性环境中：
    *   在脏方块吸地：当前方块变干净，但**有时**相邻方块也会变干净。
    *   在干净方块吸地：**有时**会把地弄脏。
*   **结果**：动作的结果不再是一个单一状态，而是一个**状态集合**。例如 $Results(1, Suck) = \{5, 7\}$。

#### 2. AND-OR 搜索树
*   由于环境的不确定性，我们的“解决方案”不能只是一个动作序列，而必须是一个**权变计划 (Contingency Plan / Strategy)**（即：如果发生情况A做动作X，发生情况B做动作Y）。
*   **OR 节点**：代表智能体（Agent）的选择。智能体选择一个动作。
*   **AND 节点**：代表环境（Environment）的选择。环境决定动作的后果（分支）。
*   **解决方案**：是一个子树，必须覆盖AND节点的所有分支（因为你不知道环境会选哪个，必须对所有结果都有应对方案）。

---

### 第五部分：Minimax 算法 (Minimax Algorithm)
*对应课件：Lecture 11 Slide 13-21*

这是对抗搜索的核心。假设对手也是理性的，并尽全力阻碍你获胜。

#### 1. 核心思想
*   **MAX玩家**：选择能通向最高效用值的动作。
*   **MIN玩家**：选择能让MAX效用最小的动作（即对自己最有利）。
*   **递归计算**：从叶子节点（终端状态）向上回溯数值。

#### 2. Minimax 公式
$$Minimax(s) = \begin{cases} Utility(s) & \text{if Terminal-Test}(s) \\ \max_{a \in Actions(s)} Minimax(Result(s, a)) & \text{if Player}(s) = \text{Max} \\ \min_{a \in Actions(s)} Minimax(Result(s, a)) & \text{if Player}(s) = \text{Min} \end{cases}$$

#### 3. 倒三角形树案例解析
*课件中使用了多个倒三角形的树来演示数值回溯（Lecture 11 Slide 15-17）：*
*   **底层（终端）**：比如数值是 5, 1, 20 (第一组); 15, 10, 8 (第二组) 等。
*   **MIN层**：MIN会在每组中选最小的。
    *   第一组 (5, 1, 20) -> MIN选 **1**。
    *   第二组 (15, 10, 8) -> MIN选 **8**。
    *   第三组 (9, 10, 11) -> MIN选 **9**。
*   **MAX层**：MAX会在MIN选出的结果(1, 8, 9)中选最大的。
    *   MAX选 **9**。
*   **结论**：这个博弈的Minimax值是9。这意味着如果双方都完美游戏，MAX最终能得到9分。

#### 4. 复杂度分析
*   **时间复杂度**：$O(b^m)$。其中 $b$ 是分支因子（每步可行走的数量），$m$ 是树的最大深度。
    *   例如国际象棋：$b \approx 35$, $m \approx 100$，节点数 $35^{100}$，完全不可计算。
*   **空间复杂度**：$O(bm)$（如果是深度优先搜索）。

---

### 第六部分：Alpha-Beta 剪枝 (Alpha-Beta Pruning)
*对应课件：Lecture 11 Slide 22-37*

为了解决Minimax效率低的问题，我们需要**剪枝**（忽略那些不会影响最终决定的分支）。

#### 1. 核心参数
*   **$\alpha$ (Alpha)**：MAX玩家在当前路径上发现的**最好（最高）**的选择的值。MAX至少能拿这么多分。
*   **$\beta$ (Beta)**：MIN玩家在当前路径上发现的**最好（最低，对MAX最差）**的选择的值。MIN最多让MAX拿这么多分。

#### 2. 剪枝逻辑
*   如果在某个节点，发现当前值 $v$ 比 $\alpha$ 还要差（对MIN来说）或者比 $\beta$ 还要好（对MAX来说），就可以停止搜索该子树。
*   **规则**：如果 $v \geq \beta$，MAX玩家就不用看了（因为MIN玩家在上层已经在另一个分支有更好的选择 $\beta$，绝不会让博弈走到现在的 $v$）。

#### 3. 详细剪枝案例 (Step-by-Step)
*课件 Slide 28-33 的树形图演示非常关键：*
1.  **初始化**：区间 $[-\infty, +\infty]$。
2.  **搜索左子树**：MAX下探，MIN发现两个叶子3和12。MIN选3。MAX现在知道自己至少能得3分（$\alpha=3$）。
3.  **搜索中间子树**：
    *   MIN先看第一个叶子8。
    *   此时 MIN 的当前值是8。但是 MAX 之前的 $\alpha=3$。8 > 3，有可能。
    *   MIN再看下一个叶子2。
    *   此时 MIN 的选择变成了2。
    *   **关键点**：MAX已经知道左边有一条路能得3分。现在中间这条路，MIN会让MAX只能得2分（或者更少）。
    *   **剪枝**：MAX绝不会走中间这条路（因为 $2 < 3$）。所以中间子树剩下的节点（如果有）都不用看了。
4.  **搜索右子树**：同理，根据 $\alpha$ 和 $\beta$ 的值不断收缩区间，一旦发现某条路不可能被理性玩家选择，直接剪掉。

#### 4. 优化：移动排序 (Move Ordering)
*   **杀手移动 (Killer Move)**：如果你能先检查那些“最好”的移动（最可能导致剪枝的移动），剪枝效率会大幅提高。
*   如果是完美排序，时间复杂度可以降低到 $O(b^{m/2})$，相当于分支因子变成了 $\sqrt{b}$。

---

### 第七部分：进一步优化 (Reducing Depth & Stochastic Games)
*对应课件：Lecture 11 Slide 38-46*

即便用了剪枝，像国际象棋这样深度的游戏也无法搜到底。

#### 1. 限制搜索深度 (Reducing Maximum Depth)
*   **截断测试 (Cutoff Test)**：不再搜到游戏结束，而是搜到深度 $d$ 就停。
*   **评估函数 (Evaluation Function / Heuristic)**：
    *   用 `Eval(s)` 代替 `Utility(s)`。
    *   **加权线性函数**：$Eval(s) = w_1 f_1(s) + w_2 f_2(s) + ...$
    *   **例子**：国际象棋中，$f_1$可能是皇后的数量，$w_1$是皇后的权重值。
    *   现代方法也可使用**机器学习**来训练这些权重。

#### 2. 随机博弈 (Stochastic Games)
*   **场景**：包含运气成分，如掷骰子（Backgammon）。
*   **机会节点 (Chance Nodes)**：除了MAX和MIN节点，还有圆形的机会节点。
*   **Expectiminimax 算法**：
    *   在机会节点，计算**期望值 (Expected Value)**，即结果的加权平均。
    *   公式：$\sum P(r) \times Expectiminimax(Result(s, r))$。
    *   *课件例子 (Slide 43)*：树结构中加入了“Chance”层，计算时需乘上概率（如 1/36, 1/18 等）。

#### 3. 蒙特卡洛搜索 (Monte Carlo Search)
*   如果状态空间太大或概率太复杂，无法计算精确期望。
*   **Rollout**：模拟几千次游戏，每次随机选择动作，直到游戏结束。
*   统计输赢的平均值作为当前状态的评估值。

---

### 第八部分：总结 (Summary)
*   对抗搜索是处理竞争性多智能体环境的关键。
*   **Minimax** 提供了理论最优解，但代价昂贵。
*   **Alpha-Beta 剪枝** 是必须的优化手段，通过排除无效分支提升效率。
*   **启发式评估函数** 允许我们在有限时间内做出决策（不搜到底）。
*   **随机博弈** 引入了概率和期望值的概念。
*   

这一部分是人工智能中最精彩、逻辑性最强的内容。我会基于 Lecture 11 的内容，通过“手把手”的计算流程，详细拆解 **Minimax（极大极小值算法）** 和 **Alpha-Beta Pruning（$\alpha-\beta$ 剪枝）**。

---

# 1. Minimax 算法 (极大极小值算法)
**核心逻辑**：假设你（MAX）绝顶聪明，对手（MIN）也绝顶聪明。你知道对手一定会选对你最不利的棋步，所以你要在“最坏的情况中找最好的”。

*   **MAX (你)**：试图让分数**最大化**。
*   **MIN (对手)**：试图让分数**最小化**。

### 计算流程 (Step-by-Step)
这个算法是**深度优先 (Depth-First)** 的，意味着它会先一路搜到底（终端节点），算出分数，然后再一层层往回传（回溯）。

1.  **下探**：从根节点开始，一直走到叶子节点（游戏结束或到达搜索深度）。
2.  **评估**：计算叶子节点的**效用值 (Utility)**。
3.  **回溯 (Backtracking)**：
    *   如果当前是 **MIN 层**：看下面所有子节点的值，选一个**最小**的传上来。
    *   如果当前是 **MAX 层**：看下面所有子节点的值，选一个**最大**的传上来。
4.  **决策**：根节点（MAX）最终得到的那个值，就是最佳策略的预期得分。

### 详细案例演示
参考 **Lecture 11, Slide 16** 的那棵树。

#### **树的结构**
*   **根节点 A (MAX)**：有三个分支，通向 B, C, D。
*   **中间层 (MIN)**：
    *   节点 B 的子节点（叶子）是：**5, 1, 20**
    *   节点 C 的子节点（叶子）是：**15, 10, 8**
    *   节点 D 的子节点（叶子）是：**9, 10, 11**

#### **计算步骤**

**第一步：处理 MIN 层（B, C, D）**
MIN 想要分越低越好。
1.  **节点 B**：面对选项 $\{5, 1, 20\}$。
    *   MIN 会选择 **1**。
    *   所以节点 B 的值变成 **1**。
2.  **节点 C**：面对选项 $\{15, 10, 8\}$。
    *   MIN 会选择 **8**。
    *   所以节点 C 的值变成 **8**。
3.  **节点 D**：面对选项 $\{9, 10, 11\}$。
    *   MIN 会选择 **9**。
    *   所以节点 D 的值变成 **9**。

**第二步：处理 MAX 层（根节点 A）**
MAX 想要分越高越好。
*   MAX 现在看到的局面是：如果走 B 路得 1 分；走 C 路得 8 分；走 D 路得 9 分。
*   选项集合 $\{1, 8, 9\}$。
*   MAX 选择 **9**。

**结论**：
*   Minimax 值为 9。
*   MAX 的最佳动作是**走向 D**。

---

# 2. Alpha-Beta 剪枝 (Alpha-Beta Pruning)
**核心逻辑**：既然我们知道对手很聪明，如果发现某条路“太烂了”（甚至不如一定要放弃的路），或者对手“太强了”（肯定会封死这条路），那就根本没必要把那条路算完。直接剪掉 (Prune)，省时间。

这需要维护两个值，并在搜索过程中不断更新：
*   **$\alpha$ (Alpha)**：**MAX** 目前找到的**保底收益**（最高值）。MAX 绝不会接受比 $\alpha$ 更差的结果。初始化为 $-\infty$。
*   **$\beta$ (Beta)**：**MIN** 目前允许的**最大损失**（最低值）。MIN 绝不会让 MAX 拿到比 $\beta$ 更高的分。初始化为 $+\infty$。

**剪枝口诀**：
> **当 $\alpha \ge \beta$ 时，剪枝！**
> (意思就是：这一支路已经没前途了，或者对手不会让你走到这儿，不用再看了)

### 详细计算流程 (Trace)
我们使用一个经典的结构来模拟剪枝过程（参考 Lecture 11 Slide 28-33 的逻辑）。

假设树结构如下：
*   **根节点 A (MAX)**
    *   左分支 -> **节点 B (MIN)**
        *   B 的叶子：**3, 12, 8**
    *   右分支 -> **节点 C (MIN)**
        *   C 的叶子：**2, 14, 5**

**初始状态**：$\alpha = -\infty, \beta = +\infty$。

#### **步骤 1：搜索左侧子树 (节点 B)**
1.  程序下探到节点 B（MIN），再下探到第一个叶子 **3**。
2.  **更新 B (MIN)**：B 发现了一个 3。因为 B 是找最小值，所以 B 暂时的值是 3。
    *   同时，B 会更新 $\beta$。对于 B 来说，它最多只给 MAX 3分。所以 B 节点的 $\beta$ 变成了 3。
3.  **检查 B 的下一个叶子 12**：
    *   12 比 3 大，MIN 不会选 12。B 的值保持 3。
4.  **检查 B 的下一个叶子 8**：
    *   8 比 3 大，MIN 不会选 8。B 的值保持 3。
5.  **B 节点搜索完毕**，返回值为 **3**。

#### **步骤 2：回到根节点 A (MAX)**
1.  A 收到了左边传来的值 3。
2.  **更新 A (MAX)**：A 是找最大值，现在手里有个 3 了。
    *   **关键更新**：A 更新自己的 $\alpha$。$\alpha = \max(-\infty, 3) = 3$。
    *   **含义**：MAX 此时心里有数了，“我至少能拿 3 分”。

#### **步骤 3：搜索右侧子树 (节点 C) —— *精彩的剪枝时刻***
带着从根节点传下来的参数：**$\alpha=3, \beta=+\infty$** 进入节点 C。

1.  程序下探到 C 的第一个叶子 **2**。
2.  **更新 C (MIN)**：C 发现了一个 2。C 是找最小值，所以 C 暂时的值变成了 2。
3.  **检查是否剪枝 ($\alpha \ge \beta$ ?)**：
    *   注意，虽然 C 节点的 $\beta$ 还是 $+\infty$（尚未被上层限制），但我们看的是**当前路径的有效性**。
    *   对于父节点 A (MAX) 来说，它手里已经攥着一个 **3** ($\alpha=3$)。
    *   现在右边的 C (MIN) 说：“我这里有个 2，如果走我这，我最多给你 2 分（甚至更低）”。
    *   MAX 一看：左边能拿 3 分，右边如果不幸走到这儿只能拿 2 分。那我**绝对不会走右边**。
    *   从数学公式看：当前 C 的暂定值 $v=2$。判断条件 $v \le \alpha$ ($2 \le 3$)。
    *   **结果**：发生 **Alpha 剪枝 (Cutoff)**。

4.  **剪枝发生**：
    *   C 节点剩下的叶子 **14** 和 **5** **根本不需要看！**
    *   因为哪怕后面有个 100 分，MIN 也会选前面的 2，MAX 只能拿到 2。而 MAX 已经在左边有 3 分了，所以右边这一坨完全没意义。

#### **最终结果**
*   根节点 A 的值选定为 3。
*   在这个例子中，我们少搜了两个节点（14和5），这就是效率的提升。

---

# 3. 随机博弈计算 (Expectiminimax)
**来源：Lecture 11 Slide 42-44**

当游戏中引入了骰子（Dice）或运气成分，Minimax 变成了 **Expectiminimax**。

**区别**：
*   **Minimax**：确定性地选最大/最小。
*   **Expectiminimax**：加入了 **Chance Node (机会节点)**，计算**加权平均值 (Weighted Average)**。

#### **计算例子**
假设根节点 A (MAX) 走一步到了 B (Chance Node)。
B 有两个可能的结果（比如掷硬币）：
1.  **50% 概率** 变成状态 C（效用值 10）。
2.  **50% 概率** 变成状态 D（效用值 2）。

**计算 B 的值**：
这不是由 MAX 或 MIN 决定的，而是由概率决定的。
$$Value(B) = (0.5 \times 10) + (0.5 \times 2) = 5 + 1 = 6$$

**计算 A 的值**：
假设 A 还有另一条确定的路 E，效用是 5。
MAX 会比较：
*   走 B 路：期望值是 6。
*   走 E 路：确定值是 5。
*   **决策**：MAX 会选 B 路（因为 $6 > 5$）。即使有风险得 2 分，但平均来看更划算。

### 总结算法计算流程图

1.  **Minimax**:
    *   底层叶子 -> 填分。
    *   MIN 层 -> 挑子节点里最小的数填上。
    *   MAX 层 -> 挑子节点里最大的数填上。
    *   一路填到根。

2.  **Alpha-Beta**:
    *   带着区间 $[-\infty, +\infty]$ 出发。
    *   MAX 发现好值 -> 提高下限 ($\alpha$)。
    *   MIN 发现坏值 -> 压低上限 ($\beta$)。
    *   一旦发现下限比上限还高 ($\alpha \ge \beta$) -> 剪刀手咔嚓，后面的不看了。

3.  **Expectiminimax**:
    *   遇到 Chance 节点 -> 算 $\text{概率} \times \text{分数}$ 的总和。