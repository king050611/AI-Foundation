
---

# 完整学习笔记：搜索算法与问题解决

## 第一部分：智能体与问题解决框架

### A. 智能体类型（Agent Types）

智能体的行为由其复杂目标驱动，通常通过**搜索**来构建长期推理和行动序列。

| 智能体类型 | 核心机制 | 内存/模型（Persistent States） |
| :--- | :--- | :--- |
| **简单反射智能体** | 仅基于当前感知和预设的**条件-动作规则**行动。 | 仅存储规则。 |
| **基于模型的反射智能体** | 利用内部模型预测世界动态和动作结果。 | 存储世界概念状态、环境动态模型、传感器动态模型和规则等。 |
| **基于目标的智能体** | **复杂目标**驱动行为；结合模型实现**长期推理**，通常通过搜索寻找动作序列。 | 必须包含目标信息。 |

### B. 问题解决智能体的流程与伪代码

问题解决智能体（Problem-solving agents）通常进行**离线（offline）规划**。

**核心伪代码：Simple-Problem-Solving-Agent**
当动作序列（`seq`）为空时，智能体重新规划：

1.  `goal ← formulateGoal(state)`：制定要达成的目的（解决问题的第一步）。
2.  `problem ← formulateProblem(state, goal)`：定义需要考虑的动作和状态。
3.  `seq ← search(problem)`：调用搜索算法，返回一个**动作序列**形式的解决方案。
4.  `action ← first(seq)`：执行序列中的第一个动作。
5.  `seq ← rest(seq)`：移除已执行的动作。
6.  `return action`：返回要执行的动作。

### C. 问题类型与表述要素

#### 1. 问题类型（Problem Types）

环境的特征决定了规划的复杂性：

| 问题类型 | 环境特点 | 解决方案形式 | 示例（真空世界） |
| :--- | :--- | :--- | :--- |
| **单状态问题** | **确定性**、**完全可观察**。 | 动作序列。 | 从状态 \#5 开始，解为 \[Right, Suck]。 |
| **一致性问题** | **不可观察**（不知道确切状态）。 | 动作序列（如果存在）。 | 从状态集 $\{1, \dots, 8\}$ 开始，解为 \[Right, Suck, Left, Suck]。 |
| **偶发性问题** | **非确定性** 和/或 **部分可观察**。 | **或然计划**（Contingent plan/策略），需要根据感知采取下一步行动。 | 吸尘可能弄脏干净地毯，解为 \[Right, **if dirt then Suck**]。 |
| **探索问题** | **未知状态空间**。 | 智能体需要在**“在线”模式**下探索。 | N/A |

#### 2. 问题表述的五要素（Single-state Problem Formulation）

1.  **初始状态（Initial state）：** 例如，“在 Arad”。
2.  **动作（Actions）：** 可行的动作，例如城市间“驾车”。
3.  **后继函数 $S(x)$：** 给定状态 $x$，返回一组**动作-新状态对**的集合。
4.  **目标测试（Goal test）：** 判断一个状态是否为目标状态，可显式（如 $x = \text{“at Bucharest”}$）或隐式（如 $\text{NoDirt}(x)$）。
5.  **路径成本（Path cost）：** 必须是**可加的**（additive），且步成本 $c(x, a, y)$ 假定 $\ge 0$。

**状态空间抽象：** 现实世界过于复杂，必须进行抽象。抽象状态指一组实际状态，抽象动作指一组复杂的实际动作，目的是让抽象动作比原始问题“更容易”解决。

## 第二部分：无信息搜索策略（Uninformed Search）

无信息搜索（Uninformed strategies）仅使用问题定义中包含的信息，不使用外部启发式知识指导方向。

### A. 搜索基础：节点、前沿与图搜索

*   **搜索过程：** 通过离线模拟状态空间探索来解决问题，即生成已探索状态的后继状态（扩展状态）。
*   **节点（Node）：** 代表一条特定的路径，包含 4 个关键组成部分：
    *   n.STATE（状态空间中对应的状态）。
    *   n.PARENT（生成当前节点的父节点）。
    *   n.ACTION（导致 n 的动作）。
    *   n.PATH-COST（从初始状态到 n 的路径成本）。
*   **前沿/边缘（Frontier or fringe）：** 已生成但**尚未扩展**的节点。
*   **图搜索（Graph Search）：** 树搜索不处理**重复状态**或循环。图搜索通过维护一个**封闭列表（closed list）**来存储所有**已扩展**的状态，只有新状态不在该列表中才会被添加到前沿，从而避免无限循环和将线性问题转化为指数问题。

### B. 搜索策略评估标准

| 标准名称 | 解释 | 参数衡量（复杂度） |
| :--- | :--- | :--- |
| **完备性 (Completeness)** | 如果存在解决方案，算法是否总能找到？ | $b$ (最大分支因子), $d$ (最优解深度), $m$ (最大深度)。 |
| **最优性 (Optimality)** | 找到的解决方案成本是否最低？ | 时间复杂度：$O(b^d)$ 或 $O(b^m)$。 |
| **时间复杂度 (Time Complexity)** | 找到解决方案所需的时间。 | 空间复杂度：$O(b^d)$ 或 $O(bm)$。 |
| **空间复杂度 (Space Complexity)** | 执行搜索所需的内存量。 | - |

### C. 具体的无信息搜索策略

| 策略名称 | 核心机制 | 前沿实现 | 完备性 | 最优性 | 时间复杂度 | 空间复杂度 |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **广度优先（BFS）** | 扩展**最浅**的未扩展节点。 | **FIFO（队列）**。 | 是。 | **是**（仅当所有步成本相等时）。 | $O(b^d)$。 | $O(b^d)$ (高)。 |
| **一致成本（UCS）** | 扩展**路径成本 $g(n)$ 最低**的节点。 | **优先队列**（按成本排序）。 | 是（前提是步成本 $\ge 0$）。 | **是**（处理不同步成本）。 | $O(b^{\lceil C^*/\epsilon \rceil})$。 | $O(b^{\lceil C^*/\epsilon \rceil})$。 |
| **深度优先（DFS）** | 扩展**最深**的节点，到达终点时回溯。 | **LIFO（栈）**。 | 否（无限深度/循环）。 | 否。 | $O(b^m)$。 | $O(bm)$（**线性空间**）。 |
| **深度限制（DLS）** | 设置最大深度限制 $L$ 的 DFS。 | 递归/堆栈。 | 否（目标超出 $L$ 时）。 | 否。 | $O(b^L)$。 | $O(bL)$。 |
| **迭代加深（IDS）** | 循环调用 DLS，逐步增加深度限制 $L=0, 1, 2, \dots$。 | - | 是。 | **是**（如果步成本 $= 1$）。 | $O(b^d)$（与 BFS 相近）。 | $O(bd)$（**线性空间**）。 |

## 第三部分：有信息搜索策略（Informed Search）

有信息搜索（Informed Search）使用**问题特有的知识**（启发式）来指导搜索，比无信息搜索效率更高。

### A. 启发式与评估函数

*   **启发式函数 $h(n)$：** 估计从当前节点 $n$ 到目标节点的最便宜路径的**成本**。如果 $n$ 是目标节点，则 $h(n)=0$。
*   **评估函数 $f(n)$：** 估计当前节点的“可取性”。搜索倾向于扩展 $f(n)$ 值最低的节点。

### B. 贪婪最佳优先搜索（Greedy Best-First Search, GBFS）

*   **目标：** 尝试扩展**最接近目标**的节点。
*   **评估函数：** $f(n) = h(n)$。
*   **机制：** 它类似于 DFS，倾向于沿着一条路径快速前进，但在遇到死胡同时会回溯。
*   **示例：** 在罗马尼亚路径问题中，使用**直线距离**作为 $h(n)$，可以快速找到目标，但**不保证最优**。

### C. A\* 搜索（A\* Search）

A\* 搜索是最常用的启发式搜索，它结合了历史成本和估计未来成本。

*   **评估函数：** $f(n) = g(n) + h(n)$。
    *   $g(n)$：从**初始状态**到节点 $n$ 的实际路径成本。
    *   $h(n)$：从节点 $n$ 到**目标**的启发式（估计）成本。
    *   $f(n)$：通过节点 $n$ 达到最便宜解决方案的**估计总成本**。
*   **机制：** 始终扩展 $f(n)$ 值最低的节点。

### D. A\* 搜索的优化性条件

A\* 搜索在特定条件下是**完备且最优的**。

1.  **容许性（Admissible Heuristic）：**
    *   **定义：** 启发式函数 $h(n)$ 是“乐观的”，它**永远不会高估**到达目标的实际成本。
    *   **作用：** 如果 $h(n)$ 是容许的，则 $f(n)$ 永远不会高估达到目标的实际成本 $C^*$。因此，A\* 保证不会在扩展最优路径上的节点之前，扩展次优目标节点 $G$。
    *   **示例：** 直线距离是容许的，因为实际驾驶距离不可能短于直线距离。

2.  **一致性/单调性（Consistent/Monotonic Heuristic）：**
    *   **定义：** 在图搜索中，要确保最优性，启发式函数必须一致。对于任何节点 $n$ 及其后继 $n'$，必须满足 $h(n) \le c(n, a, n') + h(n')$。
    *   **作用：** 如果 $h$ 一致，则沿着任何路径的 $f$ 值是**非递减**的。

### E. 启发式函数的发明与变体

*   **启发式发明：** 通常通过**放松问题**（Relaxing the problem）来发明容许启发式。放松问题相当于在状态空间图中创建了新的连接，使得解决松弛问题所需的步数**小于或等于**解决原始问题的实际成本。
    *   **示例（8-谜题）：**
        *   **错位方块数量 ($h_1$/Hamming distance)：** 估计错位方块的数量。
        *   **曼哈顿距离 ($h_2$/Manhattan distance)：** 估计每个方块到其目标位置的行/列距离之和。
*   **主导性（Domination）：** 如果对于每个非目标状态 $n$ 都有 $h_2(n) \ge h_1(n)$，则 $h_2$ **主导** $h_1$。$h_2$ 是更紧密的下界，因此效率更高。
*   **A\* 变体：**
    *   **迭代加深 A\* (IDA\*)：** 扩展了 IDS 的思想，使用 $f$ 值的上限 $U$ 代替深度限制。
    *   **加权 A\* (Weighted A\*)：** 使用 $f(n) = g(n) + W \cdot h(n)$ 探索状态。权重 $W$ 控制搜索的倾向。$W=0$ 时退化为 UCS；$W=1$ 时是标准 A\*；当 $W$ 很大时，类似于 GBFS。

## 第四部分：局部搜索与优化（Local Search）

局部搜索算法主要用于**优化问题**，即找到最优的**目标状态本身**就是解决方案，路径是无关紧要的。这类算法只保留一个“当前”状态，并不断尝试改进它，具有**恒定的空间复杂度**。

### A. 爬山算法（Hill-Climbing）

**解释：** 每一步都移动到拥有**最高值**（或最低成本）的邻居状态。

*   **停止条件：** 当找不到值更高的邻居时（即到达**局部最大值**），算法停止。
*   **局限性：** 容易陷入局部最大值、高原（函数值平坦）或山脊（可能导致搜索振荡）。
*   **随机重启爬山算法：** 从**随机选择的起始点**重复执行爬山搜索，以克服局部最大值问题。

### B. 模拟退火（Simulated Annealing, SA）

**解释：** 借鉴冶金学中的退火过程，通过允许一些**“坏”的移动**来**探索**搜索空间，并逐渐降低接受“坏”移动的频率，从而逃离局部最大值。

*   **温度 $T$：** 控制接受“坏”移动的概率 $P = e^{-\Delta E/T}$。$\Delta E$ 越大（差异越坏），接受概率越低；$T$ 越高，接受概率越高。
*   **性质：** 当 $T \to 0$ 时，行为类似于爬山算法；当 $T \to \infty$ 时，行为类似于随机游走。如果 $T$ 降低得足够慢，找到全局最优解的概率 P\[reach $x^*$ ] 接近 1。

### C. 局部束搜索（Local Beam Search）

**解释：** 维护 $k$ 个状态的集合（“束”），并并行扩展它们。

*   **机制：** 每次迭代生成所有 $k$ 个状态的所有后继状态，然后从**所有后继中选择最佳的 $k$ 个**作为下一轮的起始状态。
*   **特性：** 找到好状态的搜索会“招募”其他搜索加入。但所有 $k$ 个状态可能集中在同一个局部最优区域。
*   **随机束搜索（Stochastic beam search）：** 随机选择 $k$ 个后继，但**偏向于好的**，类似于自然选择。

### D. 遗传算法（Genetic Algorithms, GA）

**解释：** 一种基于**随机局部束搜索**的优化方法，通过结合**父代状态对**的信息生成子代。

*   **状态表示：** 状态被编码为字符串（**染色体**），其中的字符是**基因**。
*   **迭代机制：** 通过**选择、交叉和变异**操作构建下一代种群。

#### 核心操作符详解

| 操作符 | 作用倾向 | 机制解释 | 示例 |
| :--- | :--- | :--- | :--- |
| **选择（Selection）** | 偏向 | 根据**适应度（Fitness）**成比例地选择父代。适应度越高，被选中的几率越大。通常使用**轮盘赌技术**实现。 | 适应度 3、1、2 的个体，被选中概率分别为 $50\%、17\%、33\%$。 |
| **交叉（Crossover）** | **探索（Exploration）** | 结合两个父代的信息生成子代。例如，**1-点交叉**随机选择一个点，交换父母代的尾部片段。 | 交叉是**唯一**可以结合两个父代信息的操作。 |
| **变异（Mutation）** | **利用（Exploitation）** | 以一个小的**变异率 $P_m$** 独立地改变子代的基因。用于在有前景的区域内优化。 | 变异是**唯一**可以引入新信息（新的等位基因）的操作。 |

## E. 连续状态空间（Continuous state spaces）

迭代改进方法也适用于状态空间是连续的优化问题。

**示例：** 在罗马尼亚定位三个机场的问题。这是一个 6 维状态空间，目标函数是最小化每个城市到最近机场的平方距离之和。

**优化方法：**

1.  **离散化方法：** 将连续空间转化为离散空间。例如，通过经验梯度考虑每个坐标上 $\pm \delta$ 的变化。
2.  **梯度方法：** 计算梯度 $\nabla f$ 来增加或减少目标函数 $f$，例如通过 $x \leftarrow x + \alpha \nabla f(x)$ 来更新状态。

---

$$算法补充$$
没问题！Lecture 10 的 **Slide 1-8** 实际上是对之前课程学过的核心搜索算法的**复习（Recap）**。虽然课件上写得比较概括，但要理解这些不仅对考试很重要，也是理解后面“对抗搜索”的基石。

下面我将把 **无信息搜索**、**有信息搜索**、**A*搜索** 和 **局部搜索** 的原理、计算公式和详细流程全部拆解出来。

---

### 1. 无信息搜索 (Uninformed Search)
*对应 Slide 5*

#### **原理**
*   **别名**：盲目搜索 (Blind Search)。
*   **核心**：除了问题定义（起点、终点、能怎么走）之外，没有任何关于“目标在哪里”的线索。就像在浓雾中找路，只能摸索。
*   **典型算法**：广度优先搜索 (BFS)、深度优先搜索 (DFS)、一致代价搜索 (UCS)。

#### **计算与执行流程**
这里没有复杂的公式，主要是**扩展顺序**的不同。

1.  **初始化**：把起点放入一个列表（边缘集合/Frontier）。
2.  **循环**：
    *   如果列表空了，失败。
    *   从列表中取出一个节点（BFS取最早放进去的，DFS取最后放进去的）。
    *   **测试**：这是目标吗？如果是，停止。
    *   **扩展**：如果不是，找出它所有能走的邻居节点，把它们放入列表。
3.  **低效原因**：它不知道东南西北，会把所有错误的方向都试一遍，计算量随深度呈指数级爆炸 ($b^d$)。

---

### 2. 有信息搜索 (Informed Search) / 最佳优先搜索
*对应 Slide 6*

#### **原理**
*   **核心**：利用**启发式信息 (Heuristic)**。虽然不知道确切路径，但我能猜出“哪个节点离目标看起来更近”。
*   **评估函数 $f(n)$**：给每个节点打分，分数代表“合意度”（Desirability）。
*   **贪心策略**：永远先走那个**看起来**分数最好的节点。

#### **计算流程**
1.  **使用数据结构**：优先队列 (Priority Queue)。队列里的元素按 $f(n)$ 从小到大排序。
2.  **流程**：
    *   计算起点的 $f(start)$，放入队列。
    *   **Pop**：弹出队列中 $f(n)$ 最小的节点。
    *   **Expand**：生成它的邻居。
    *   **Calc**：计算邻居的 $f(neighbor)$。
    *   **Push**：把邻居放入队列。

---

### 3. A* 搜索算法 (A-Star Search) —— **核心考点**
*对应 Slide 7*

A* 是目前最流行的寻路算法，因为它结合了“已知的代价”和“预测的代价”。

#### **核心公式**
$$f(n) = g(n) + h(n)$$

*   **$g(n)$ (Backward Cost / 实际代价)**：
    *   从**起点**走到当前节点 $n$，**实际上**花了多少路程/时间/油费。
    *   *怎么算*：父节点的 $g$ + 父节点到这里的距离。
*   **$h(n)$ (Heuristic Cost / 启发代价)**：
    *   从当前节点 $n$ 到**终点**，**估计**还要走多远。
    *   *怎么算*：通常是直线距离（欧几里得距离）或者曼哈顿距离。这是一个猜测值。
*   **$f(n)$ (Total Estimated Cost / 总评估代价)**：
    *   经过节点 $n$ 这条路，总共大概要花多少代价。

#### **详细计算案例 (Step-by-Step)**
假设地图如下：
*   **起点 S**，**终点 G**。
*   **路径**：
    *   S -> A (距离 1)
    *   S -> B (距离 4)
    *   A -> G (距离 5)
    *   B -> G (距离 1)
*   **启发值 h(n)** (这是题目给定的“预测”距离)：
    *   $h(S) = 5$
    *   $h(A) = 6$
    *   $h(B) = 2$
    *   $h(G) = 0$ (到了终点距离当然是0)

**计算流程：**

1.  **初始化**：
    *   看起点 S。
    *   $g(S) = 0$ (还没动)。
    *   $h(S) = 5$。
    *   **$f(S) = 0 + 5 = 5$**。
    *   优先队列：`[(S, 5)]`

2.  **第一轮扩展 (拿出 S)**：
    *   S 有两个邻居：A 和 B。
    *   **计算 A**：
        *   $g(A) = g(S) + \text{dist}(S,A) = 0 + 1 = 1$。
        *   $h(A) = 6$ (给定)。
        *   **$f(A) = 1 + 6 = 7$**。
    *   **计算 B**：
        *   $g(B) = g(S) + \text{dist}(S,B) = 0 + 4 = 4$。
        *   $h(B) = 2$ (给定)。
        *   **$f(B) = 4 + 2 = 6$**。
    *   优先队列排序（小的在前）：`[(B, 6), (A, 7)]`

3.  **第二轮扩展 (拿出 B)**：
    *   为什么拿 B？因为 $f(B)=6$ 小于 $f(A)=7$。即使 B 实际走的远，但因为它离终点看起来很近，所以优先试探。
    *   B 的邻居是 G。
    *   **计算 G**：
        *   $g(G) = g(B) + \text{dist}(B,G) = 4 + 1 = 5$。
        *   $h(G) = 0$。
        *   **$f(G) = 5 + 0 = 5$**。
    *   优先队列：`[(G, 5), (A, 7)]`

4.  **第三轮扩展 (拿出 G)**：
    *   取出 G，发现是目标。
    *   **搜索结束**。找到路径 S -> B -> G，总代价 5。

---

### 4. 局部搜索 (Local Search)
*对应 Slide 8*

#### **原理**
*   **区别**：前面的 A* 关注**路径**（怎么去）。局部搜索只关注**状态**（结果好不好）。
*   **适用**：比如“8皇后问题”或者“排课表”，我不关心你是怎么把皇后放上去的，我只关心最后皇后们别打架就行。
*   **目标**：找到一个让**目标函数 (Objective Function)** 最大化（或最小化）的状态。

#### **算法 1：爬山法 (Hill Climbing)**
这是一种“贪心”的局部搜索。

*   **比喻**：你在大雾中爬山，看不见山顶。你只能看脚下，哪边地势高就往哪边走一步。
*   **计算流程**：
    1.  **当前状态 (Current)**：比如现在的 $Value = 10$。
    2.  **生成邻居**：看看周围稍微改动一点后的状态。
        *   邻居1 $Value = 8$
        *   邻居2 $Value = 12$
    3.  **比较**：
        *   如果邻居(12) > 当前(10)，**移动**到邻居2。
        *   如果所有邻居都比当前低，**停止**（认为到了山顶）。
*   **缺点**：容易卡在**局部最优 (Local Maxima)**。比如你到了一个小山坡顶，周围都比你低，你就停了，但其实旁边还有座珠穆朗玛峰你没看见。

#### **算法 2：遗传算法 (Genetic Algorithms)**
这是一种模拟生物进化的随机搜索。

*   **计算流程**：
    1.  **种群初始化 (Population)**：随机生成 100 个解决方案（比如 100 种排课方案）。
    2.  **适应度评估 (Fitness)**：给每个方案打分（冲突少的得分高）。
    3.  **选择 (Selection)**：分数高的方案有更大概率被留下来“生孩子”。
    4.  **交叉 (Crossover)**：选两个父代方案，把它们的一半拼在一起，生成新方案。
    5.  **变异 (Mutation)**：随机改动新方案里的某一个点（为了防止死循环，增加多样性）。
    6.  **迭代**：重复以上步骤，直到找到满意的解。

### 总结
*   **无信息搜索**：瞎找，靠运气和穷举。
*   **A* 搜索**：靠 $f = g + h$ 公式找，既考虑实际花费，也考虑预测距离，是找路径的神器。
*   **局部搜索**：只在乎结果，通过不断微调当前状态来逼近最优解（爬山、进化）。