
---

# 局部搜索与优化算法学习笔记
**(Local Search and Optimization Algorithms)**

## I. 局部搜索概述 (Introduction)

局部搜索算法主要用于解决**优化问题**。在这类问题中，我们关注的是找到**最优的目标状态本身**（如成本最低的配置、冲突最少的排班），而达到该目标的路径无关紧要。

### 1. 核心特性
*   **状态空间（State Space）：** 由一组候选解组成。目标是找到满足约束的解或目标函数值最优的解。
*   **迭代改进（Iterative Improvement）：** 算法只保留一个（或少量）“当前”状态，通过不断移动到邻居状态来改进当前解。
*   **空间效率：** 通常只占用常数级的内存空间（Constant space）。
*   **适用场景：** 既适用于离线搜索，也适用于在线搜索。

### 2. 典型应用
*   **N 皇后问题：** 目标是在 $N \times N$ 棋盘上放置 $N$ 个皇后，使其互不攻击。
*   **旅行推销员问题（TSP）：** 寻找访问所有城市并返回起点的最短路径。
*   **资源调度/排课：** 寻找无时间冲突的最佳资源分配。

---

## II. 爬山算法 (Hill-Climbing)

**核心思想：**  
一种贪婪的迭代搜索算法。形象地比喻为“在浓雾中攀登珠峰”，只能看到脚下的坡度，每一步都向更高（或更低，取决于优化目标）的地方移动。

### 1. 算法流程（以最大化目标为例）
1.  **初始化：** 生成一个随机的初始状态 `current`。
2.  **循环：**
    *   考察 `current` 的所有邻居状态。
    *   选择值最高的邻居 `next`。
    *   如果 `Value[next] <= Value[current]`，说明已经到达局部最高点，算法停止并返回 `current`。
    *   否则，移动到 `next` (`current ← next`)。

### 2. 变体与局限
*   **局限性：** 容易陷入 **局部最大值（Local Maxima）**、**高原（Plateaux，平坦区域）** 或 **山脊（Ridges）**。
*   **改进：随机重启爬山法 (Random-Restart Hill-Climbing)**
    *   策略：如果陷入局部最优，就随机生成一个新的初始状态重新开始。
    *   结论：随着重启次数趋向无穷，找到全局最优解的概率趋近于 1。

---

## III. 模拟退火 (Simulated Annealing)

**核心思想：**  
为了解决爬山算法容易陷入局部最优的问题，模拟退火允许算法在搜索过程中做出**“坏”的移动**（移动到较差的状态），以期跳出局部陷阱。

### 1. 机制
*   借鉴物理学中金属退火的过程（加热后缓慢冷却以增强结晶）。
*   引入**温度参数 $T$**。开始时 $T$ 很高，允许大幅度的随机移动；随着时间推移，$T$ 逐渐降低，算法变得越来越“保守”，最终趋向于贪婪搜索。

### 2. 伪代码逻辑
*   随机选择一个后继状态 `next`。
*   计算能量差 $\Delta E = Value(next) - Value(current)$。
*   **如果是好移动** ($\Delta E > 0$)：直接接受。
*   **如果是坏移动** ($\Delta E \le 0$)：以概率 $P = e^{\Delta E / T}$ 接受该移动。
    *   温度 $T$ 越高，接受坏移动的概率越大。
    *   差异 $\Delta E$ 越小，接受坏移动的概率越大。

---

## IV. 局部束搜索 (Local Beam Search)

**核心思想：**  
不再只保留 1 个当前状态，而是同时维护 **$k$ 个状态**。

### 1. 流程
1.  随机生成 $k$ 个初始状态。
2.  在每一步，生成所有 $k$ 个状态的所有后继状态。
3.  从所有后继状态中，通过评估函数选出**最好的 $k$ 个**，作为下一轮的状态集合。

### 2. 特性
*   **信息共享：** 与 $k$ 次独立的随机重启搜索不同，束搜索中的状态会“招募”其他资源到有希望的区域（如果一个状态发现了好的区域，下一轮这 $k$ 个点大部分会集中到这里）。
*   **风险：** $k$ 个状态可能会迅速聚集在同一个局部峰值上，导致缺乏多样性。
*   **改进：随机束搜索 (Stochastic Beam Search)** —— 也就是**遗传算法**的前身，选择后继时引入概率，模仿自然选择。

---

## V. 遗传算法 (Genetic Algorithms, GA)

**核心思想：**  
一种受生物进化论启发的**随机局部束搜索**变体。它通过结合两个父代状态的信息来生成新的状态（子代）。

### 1. 核心概念
*   **种群 (Population)：** 一组个体的集合（类似束搜索中的 $k$ 个状态）。
*   **个体 (Individual)：** 一个解，通常编码为字符串或数字序列（染色体）。
*   **适应度函数 (Fitness Function)：** 评估个体好坏的标准，适应度越高的个体生存和繁衍的概率越大。

### 2. 三大核心操作符 (Operators)

#### A. 选择 (Selection)
*   **目的：** 决定哪些个体能成为父母。
*   **机制：** 轮盘赌选择（Roulette Wheel Selection）。个体的适应度越高，被选中的概率越大。
*   **公式：** $P(i) = \frac{Fitness(i)}{\sum Fitness}$

#### B. 交叉 (Crossover) —— 探索 (Exploration)
*   **目的：** 结合两个父代的特征，试图产生更优秀的后代。
*   **机制：** 随机选择一个“切分点”，交换父代的片段。这是 GA 区别于其他算法最关键的特征。

#### C. 变异 (Mutation) —— 利用 (Exploitation)
*   **目的：** 维持种群多样性，防止过早收敛。
*   **机制：** 以极低的概率随机修改子代中的某个基因。

---

### 3. [重点] 案例详解：遗传算法求解 8 皇后问题
*(基于您提供的图片解析)*

下图展示了遗传算法解决 8 皇后问题的一次完整迭代过程：

![GA Example](https://i.imgur.com/example_placeholder.jpg) *(此处对应您的图片)*

#### Step 1: 状态表示 (Encoding)
*   **染色体：** 图片左侧的方框（如 `24748552`）。
*   **含义：** 这是一个 8 位数字串。第 $i$ 位的数字代表棋盘上第 $i$ 列皇后所在的行号。
    *   `24748552` 意味着：第1列皇后在第2行，第2列在第4行……

#### Step 2: 适应度评估 (Fitness)
*   **目标：** 最大化互不攻击的皇后对数。8个皇后的最大可能非攻击对数是 28 ($C_8^2$)。
*   **数据解读：**
    *   **红色数字 (Fitness):** 如 24, 23, 20, 11。数值越大越好。
    *   **蓝色百分比 (Probability):** 如 31%, 29%。这是基于适应度计算出的被选中概率。适应度为 24 的个体有最高概率 (31%) 传递基因。

#### Step 3: 选择 (Selection)
*   **优胜劣汰：**
    *   适应度最高的两个个体（24 和 23）被选中进入下一环节。
    *   适应度为 23 的个体因为运气和实力，被选中了**两次**（参与两组繁殖）。
    *   适应度最低的个体（11）未被选中，其基因就此**淘汰**。

#### Step 4: 交叉 (Crossover)
*   **操作：** 选中的父母两两配对，在随机位置切开并交换尾部。
*   **示例：**
    *   **父代1:** `32752411` (灰色部分保留)
    *   **父代2:** `24748552` (白色部分拼接)
    *   **子代:** `327` + `48552` = `32748552`
    *   **意义：** 子代继承了父代1的前半部分优良特征和父代2的后半部分特征。

#### Step 5: 变异 (Mutation)
*   **操作：** 子代生成后，每一个基因位都有极小的概率发生突变。
*   **示例：** 图片最右侧，第一个子代的第 6 位数字从 `5` 突变成了 `1` (`32748`**`1`**`52`)。
*   **意义：** 这引入了父母双方都没有的新基因信息，可能正好解开了之前的冲突。

---

## VI. 连续状态空间的搜索 (Continuous State Spaces)

当状态由连续变量定义时（例如：寻找机场的最佳坐标 $(x, y)$），传统的离散方法需要调整。

1.  **离散化 (Discretization)：** 将连续空间划分为网格，但这可能导致状态空间爆炸。
2.  **梯度法 (Gradient Methods)：**
    *   利用数学导数来确定搜索方向。
    *   计算目标函数 $f$ 的梯度 $\nabla f$（即函数增长最快的方向）。
    *   **更新规则：** $x \leftarrow x + \alpha \nabla f(x)$ （$\alpha$ 为步长）。
    *   这相当于在连续地形上进行爬山算法。