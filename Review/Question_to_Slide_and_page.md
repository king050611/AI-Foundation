复习要点与出处对照

**1、图灵测试**
*   理解其核心目的，即测试机器是否能展现出与人类无法区分的智能行为。 **(出处：Slide 1 Page 20-36)**

**2、搜索算法**
*   **A*搜索算法**：掌握其核心评价函数 $f(n)=g(n)+h(n)$，其中 $g(n)$ 是从起点到当前节点 $n$ 的实际代价， $h(n)$ 是从 $n$ 到目标节点的启发式估计代价。 **(出处：Lecture 7, Page 6)**
*   **可采纳启发式**：理解其定义（启发式估计值 $h(n)$ 永远不会超过从 $n$ 到目标的实际最小代价）及其重要性（保证 A* 算法找到的解是最优路径）。 **(出处：Lecture 7, Page 10 [定义] & Page 17 [证明])**

**3、人工智能中的规划技术**
*   **Graphplan**：了解其优缺点，特别是其可能生成大量无关基原子的问题，以及通过为变量和常量分配数据类型来部分缓解该问题的方法。 **(出处：Lecture 26, Slide 24)**
*   **STRIPS规划**：理解在目标状态回溯时，为何只考虑“相关动作”可以显著减小状态空间、降低搜索复杂度。 **(出处：Lecture 27, Slide 16)**
*   **前向搜索与后向搜索**：其中前向搜索是从初始状态开始，正向应用动作，直到达到目标；后向搜索是从目标开始，通过“回归”操作逆向选择动作，直到达到初始状态。 **(出处：Lecture 27, Slide 14-15 [前向] & Slide 16-19 [后向])**

**4、不确定性决策与概率**
*   **期望效用**：掌握其定义和计算方法，即所有可能结果的效用值以其发生概率为权重的加权平均值 $E(U)=\Sigma P(X_i)*U(X_i)$。 **(出处：Lecture 19, Page 9-10)**
*   **独立事件概率**：计算多个独立事件同时发生的概率，即各自概率的乘积。 **(出处：Lecture 19, Page 22, 25, 30)**

**5、机器学习核心概念**
*   **偏差-方差权衡**：理解其核心思想，即在模型复杂度选择中，需要在偏差（欠拟合）和方差（过拟合）之间找到一个最佳平衡点，而非单纯最小化或最大化其中之一。 **(出处：Lecture 37, Slide 21-24)**
*   **学习范式**：区分监督学习、无监督学习和强化学习，并理解强化学习主要用于训练智能体进行序贯决策。 **(出处：Lecture 37, Slide 13, 15-17; Lecture 44, Slide 9)**
*   **监督学习（回归问题）**：
    *   **损失函数选择**：对于房价预测等连续值预测（回归）问题，通常选择均方误差作为损失函数，而非用于分类的交叉熵损失。 **(出处：Lecture 39, Slide 9; Loss Function相关可见 Slide 12)**
    *   **目标函数**：理解目标是最小化所有训练样本上的损失函数之和（或平均值）。 **(出处：Lecture 39, Slide 9)**
    *   **梯度下降**：理解梯度的概念，它是目标函数对模型参数的偏导数，指明了参数更新的方向，用于优化模型。 **(出处：Lecture 39, Slide 6, 11, 12)**

**6、约束满足问题（CSP）**
*   **CSP定义**：理解其由变量、变量的域以及约束条件三部分组成。 **(出处：Lecture 13, Slide 7)**
*   **回溯算法**：掌握其作为解决 CSP 的核心技术的思想，即通过递归地尝试为变量赋值，并在违反约束时“回溯”到上一步进行重新尝试。 **(出处：Lecture 14, Slide 6-7)**

**7、数据科学与负责任的人工智能**
*   **数据偏差**：了解训练数据中存在的偏差问题，例如类别不平衡。 **(出处：Lecture 46, Page 14)**
*   **去偏方法**：掌握针对类别不平衡的常见处理方法，如对少数类进行过采样。 **(出处：Lecture 46, Page 14)**
*   **可解释人工智能**：理解其目标是让 AI 系统能够为其决策或输出提供人类可以理解的解释。 **(出处：Lecture 47, Page 17-18)**